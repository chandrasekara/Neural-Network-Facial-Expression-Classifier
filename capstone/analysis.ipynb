{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "\n",
    "## Capstone Project\n",
    "\n",
    "### Using Computer Vision for Facial Expression Classification\n",
    "\n",
    "This project seeks to investigate the use of computer vision techniques to build a classifier that can classify different faces, based on facial expressions.\n",
    "\n",
    "The effectiveness of different convolutional neural network architectures will be investigated. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.alayers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-698c48fe5c2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras.alayers'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.alayers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "from keras import backend as K\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset can be obtained from [here](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge). For the purpose of this notebook, and determining the best classification model, only the first 15,000 entries will be used. Later, the entire dataset will be used for training, testing and validation on the optimal model, to gain an idea for the true performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"fer2013cp.csv\")\n",
    "\n",
    "labels = data['emotion']\n",
    "\n",
    "features = data.drop(['emotion','Usage'], axis=1, inplace=False)\n",
    "\n",
    "\n",
    "temp_list = []\n",
    "\n",
    "for i in features['pixels']:\n",
    "    temp_list.append(i.split())\n",
    "    \n",
    "features.drop('pixels',axis=1,inplace=True)\n",
    "\n",
    "features['pixels'] = pd.Series(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,labels,test_size = 0.2, random_state=0)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def df_to_tensor(X_in, im_dim, reshape=True, triple_channels=False):\n",
    "    \n",
    "    # convert from the dataframe which contains \n",
    "    \n",
    "    list_of_2d_arrays = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for image in X_in['pixels']:\n",
    "        pixel_array = []\n",
    "        \n",
    "        for pixel in image:\n",
    "            if not triple_channels:\n",
    "                pixel_array.append(int(pixel))\n",
    "            else:\n",
    "                pixel_array.append([int(pixel),int(pixel),int(pixel)])\n",
    "        \n",
    "        pixel_array = [pixel_array[x:x+im_dim] for x in range(0,len(pixel_array),im_dim)]\n",
    "        \n",
    "        \n",
    "        \n",
    "        list_of_2d_arrays.append(pixel_array)\n",
    "        \n",
    "    np_arr =  np.array(list_of_2d_arrays)\n",
    "    \n",
    "    #print(np_arr.shape)\n",
    "    if reshape:\n",
    "        return np_arr.reshape(np_arr.shape[0], 48, 48, 1)\n",
    "    else:\n",
    "        return np_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = df_to_tensor(X_train,48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_number = 21\n",
    "\n",
    "two_d_array = samples[seed_number].reshape(48,48)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "num_rows = 3\n",
    "\n",
    "num_columns = 3\n",
    "\n",
    "hardcoded_labels = [\"Angry\", \"Fear\", \"Sad\", \"Happy\", \"Surprise\",\n",
    "                   \"Happy\", \"Happy\", \"Angry\", \"Sad\"]\n",
    "\n",
    "for i in range(num_rows*num_columns):\n",
    "    ax = fig.add_subplot(num_rows,num_columns,i + 1)\n",
    "    ax.imshow(samples[seed_number + i].reshape(48,48), cmap='gray')\n",
    "    ax.title.set_text(hardcoded_labels[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEKCAYAAADq59mMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHlVJREFUeJzt3X+8VVWd//HXWzCBFJUgMlAvOaippQNkNtZkaWlZaZNT\n2g+xHKykzCYb0emRVuN36FGaWZmplWI/DC0Tf4cUZk6KoBagIY5i/kxqLMIMRT/fP9Y6cO7l3nv2\nhrPvOYf7fj4e53H3XvvH+Zxz9zmfs9bae21FBGZmZmVs0eoAzMys8zh5mJlZaU4eZmZWmpOHmZmV\n5uRhZmalOXmYmVlpTh5mZlaak4eZmZXm5GFmZqUNbXUAVRk9enR0dXW1Ogwzs46yaNGiP0bEmEbr\nbbbJo6uri4ULF7Y6DDOzjiLpwSLrudnKzMxKc/IwM7PSnDzMzKw0Jw8zMyvNycPMzEpz8jAzs9Kc\nPMzMrDQnDzMzK83Jw8zMSttsrzA3a7auGde0OoRuVsw8tNUh2CDmmoeZmZXm5GFmZqU5eZiZWWlO\nHmZmVpqTh5mZlebkYWZmpTl5mJlZaU4eZmZWmpOHmZmV5uRhZmalOXmYmVlpTh5mZlaak4eZmZXm\n5GFmZqU5eZiZWWlOHmZmVpqTh5mZlebkYWZmpVWaPCR9UtJSSUsk/VDSMEmjJM2VtDz/3b5u/VMk\n3SdpmaSD68onS1qcl50jSVXGbWZm/asseUgaB5wATImIvYAhwJHADGBeREwE5uV5JO2Rl+8JHAKc\nK2lI3t03gWnAxPw4pKq4zcyssaqbrYYCwyUNBUYAjwKHARfn5RcDh+fpw4BLI2JNRDwA3AfsK2kH\nYGRE3BoRAcyq28bMzFqgsuQREY8AXwZ+DzwG/CUifgaMjYjH8mqPA2Pz9DjgobpdPJzLxuXpnuUb\nkHScpIWSFq5cubJpr8XMzLqrstlqe1JtYgLwUuCFkt5fv06uSUSznjMizo+IKRExZcyYMc3arZmZ\n9VBls9VBwAMRsTIingV+AvwT8IfcFEX++0Re/xFgx7rtx+eyR/J0z3IzM2uRKpPH74H9JI3IZ0cd\nCNwDzAGm5nWmAlfm6TnAkZK2kjSB1DG+IDdxrZK0X97P0XXbmJlZCwytascRcZuky4E7gLXAncD5\nwNbAbEnHAg8C787rL5U0G7g7rz89Ip7LuzseuAgYDlyXH2Zm1iKVJQ+AiDgNOK1H8RpSLaS39c8A\nzuilfCGwV9MDNDOzjeIrzM3MrDQnDzMzK83Jw8zMSnPyMDOz0pw8zMysNCcPMzMrzcnDzMxKc/Iw\nM7PSnDzMzKw0Jw8zMyutUPKQtLOkg/L0cEnbVBuWmZm1s4bJQ9I04HLgW7loPPDTKoMyM7P2VqTm\nMR3YH1gFEBHLgRdXGZSZmbW3IsljTUQ8U5vJ9yNv2t3/zMys8xRJHjdJOhUYLulNwGXAVdWGZWZm\n7axI8pgBrAQWAx8GrgU+U2VQZmbW3orcDGo48J2IuABA0pBc9rcqAzMzs/ZVpOYxj5QsaoYDN1YT\njpmZdYIiyWNYRKyuzeTpEdWFZGZm7a5I8nhK0qTajKTJwNPVhWRmZu2uSJ/HicBlkh4FBLwEeE+l\nUZmZWVtrmDwi4nZJuwO75aJlEfFstWGZmVk7K1LzAHgV0JXXnySJiJhVWVRmZtbWGiYPSZcAuwB3\nAc/l4gCcPMzMBqkiNY8pwB4R4SFJzMwMKHa21RJSJ7mZmRlQrOYxGrhb0gJgTa0wIt5RWVRmZtbW\niiSP06sOwszMOkuRU3VvkrQzMDEibpQ0AhhSfWhmZtauNuZOguPwnQTNzAY130nQzMxK850Ezcys\nNN9J0MzMSvOdBM3MrLR+z7bKdw2cFRHvAy4YmJDMzKzd9VvziIjngJ0lvWCA4jEzsw5Q5CLB+4Fb\nJM0BnqoVRsRZlUVlZtYhumZc0+oQulkx89ABeZ4ifR7/C1yd192m7tGQpO0kXS7pd5LukfQaSaMk\nzZW0PP/dvm79UyTdJ2mZpIPryidLWpyXnSNJ5V6mmZk1U5ErzD+3Cfv/KnB9RByRm75GAKcC8yJi\npqQZpA75kyXtARwJ7Am8FLhR0q656eybwDTgNlKH/SHAdZsQl5mZbYIi9/P4Bb1c1xERb2yw3bbA\nPwPH5PWfAZ6RdBhwQF7tYmA+cDJwGHBpRKwBHpB0H7CvpBXAyIi4Ne93FnA4Th5mDQ3WJhWrXpE+\nj5PqpocB7wLWFthuAukU3+9K2htYBHwCGBsRj+V1HgfG5ulxwK112z+cy57N0z3LzcysRYo0Wy3q\nUXRLHp69yL4nAR+PiNskfZXURFW/75DUtKvVJR0HHAew0047NWu3ZmbWQ5GBEUfVPUbnjuxtC+z7\nYeDhiLgtz19OSiZ/kLRD3vcOwBN5+SPAjnXbj89lj+TpnuUbiIjzI2JKREwZM2ZMgRDNzGxjFDnb\nahGwMP/9NfAp4NhGG0XE48BDknbLRQcCdwNzgKm5bCpwZZ6eAxwpaStJE4CJwILcxLVK0n75LKuj\n67YxM7MWKNJsNWET9v9x4Pv5TKv7gQ+SEtZsSccCDwLvzs+zVNJsUoJZC0zPZ1oBHA9cBAwndZS7\ns9zMrIWKnG01Hfh+RPw5z28PHBUR5zbaNiLuAqb0sujAPtY/Azijl/KFwF6Nns/MzAZGkWarabXE\nARART5KuuTAzs0GqSPIYUn9Fdx4s0WNdmZkNYkWu87ge+JGk2m1oP5zLzMxskCqSPE4mXTvx0Tw/\nF7iwsojMzKztFUkew4ELIuI8WNdstRXwtyoDMzOz9lWkz2MeKYHUDAdurCYcMzPrBEWSx7CIWF2b\nydMjqgvJzMzaXZHk8ZSkSbUZSZOBp6sLyczM2l2RPo8TgcskPQoIeAnwnkqjMjOztlZkeJLbJe0O\n1MaoWhYRz1YblpmZtbN+k4ekFwPTSXf3A1gKfIP1I+Gamdkg1Gefh6T9gdvz7Kz8AFiQl5mZ2SDV\nX83jTODwiLizrmyOpCuAbwGvrjQyMzNrW/2dbTWyR+IA1o2Uu011IZmZWbvrL3koD7/es3BUg+3M\nzGwz11+z1VeAn0k6Cbgjl00GvpiXmW20rhnXtDqEblbMPLTVIZh1lD6TR0Scn6/t+ALpbKsg3eXv\nvyLiqgGKz8zM2lC/p+pGxNXA1QMUi5mZdQj3XZiZWWlFhicZdNweb2bWv/4uEvxE/usLAs3MrJv+\nmq0+mP9+bSACMTOzztFfs9U9kpYDL5X027pyARERr6w2NDMza1f9nap7lKSXADcA7xi4kMzMrN01\nOlX3cWBvSS8Ads3FHpLdzGyQa3i2laTXk0bUXUFqstpR0tSI+GXFsZmZWZsqcqruWcCbI2IZgKRd\ngR+ShioxM7NBqMhFglvWEgdARNwLbFldSGZm1u6K1DwWSroQ+F6efx+wsLqQzMys3RVJHh8l3Yr2\nhDx/M3BuZRGZmVnba5g8ImINqd/jrOrDMTOzTuCBEc3MrDQnDzMzK61h8pD0ioEIxMzMOkeRmse5\nkhZIOl7StpVHZGZmba9h8oiI15FOz90RWCTpB5LeVHlkZmbWtgr1eUTEcuAzwMnA64FzJP1O0r9U\nGZyZmbWnIn0er5T0FeAe4I3A2yPi5Xn6KwW2HyLpTklX5/lRkuZKWp7/bl+37imS7pO0TNLBdeWT\nJS3Oy86RpI14rWZm1iRFah5fA+4A9o6I6RFxB0BEPEqqjTTyCVLiqZkBzIuIicC8PI+kPYAjgT2B\nQ0h9LUPyNt8EpgET8+OQAs9rZmYVKZI8DgV+EBFPA0jaQtIIgIi4pL8NJY3P219YV3wYcHGevhg4\nvK780ohYExEPAPcB+0raARgZEbdGRJBG+D0cMzNrmSLJ40ZgeN38iFxWxNnAfwDP15WNjYjH8vTj\nwNg8PQ54qG69h3PZuDzds9zMzFqkyNhWwyJidW0mIlbXah79kfQ24ImIWCTpgN7WiYiQFIWjbfyc\nxwHHAey0007N2q2ZDaCuGde0OoRuVsw8tNUhtKUiNY+nJE2qzUiaDDxdYLv9gXdIWgFcCrxR0veA\nP+SmKPLfJ/L6j5BOB64Zn8seydM9yzcQEedHxJSImDJmzJgCIZqZ2cYokjxOBC6TdLOkXwE/Aj7W\naKOIOCUixkdEF6kj/OcR8X5gDjA1rzYVuDJPzwGOlLSVpAmkjvEFuYlrlaT98llWR9dtY2ZmLVBk\nVN3bJe0O7JaLNvUe5jOB2ZKOBR4E3p2fZ6mk2cDdwFpgekQ8l7c5HriI1PdyXX6YmVmLFOnzAHgV\n0JXXnySJiJhV9EkiYj4wP0//CTiwj/XOAM7opXwhsFfR5zMzs2o1TB6SLgF2Ae4CajWB2imzZmY2\nCBWpeUwB9sjXWJiZmRXqMF8CvKTqQMzMrHMUqXmMBu6WtABYUyuMiHdUFpWZmbW1Isnj9KqDMDOz\nzlLkVN2bJO0MTIyIG/PV5UMabWdmZpuvIkOyTwMuB76Vi8YBP60yKDMza29FOsynk4YaWQXrbgz1\n4iqDMjOz9lYkeayJiGdqM5KGkq7zMDOzQapI8rhJ0qnA8Hzv8suAq6oNy8zM2lmR5DEDWAksBj4M\nXEuxOwiamdlmqsjZVs8DF+SHmZlZobGtHqCXPo6IeFklEZmZWdsrOrZVzTDgX4FR1YRjZmadoGGf\nR0T8qe7xSEScDfi+jGZmg1iRZqtJdbNbkGoiRe8DYmZmm6EiSeDMuum1wAry3f/MzGxwKnK21RsG\nIhAzM+scRZqt/r2/5RFxVvPCMTOzTlD0bKtXAXPy/NuBBcDyqoIyM7P2ViR5jAcmRcRfASSdDlwT\nEe+vMjAzM2tfRYYnGQs8Uzf/TC4zM7NBqkjNYxawQNIVef5w4OLqQjIzs3ZX5GyrMyRdB7wuF30w\nIu6sNiwzM2tnRZqtAEYAqyLiq8DDkiZUGJOZmbW5IrehPQ04GTglF20JfK/KoMzMrL0VqXm8E3gH\n8BRARDwKbFNlUGZm1t6KJI9nIiLIw7JLemG1IZmZWbsrkjxmS/oWsJ2kacCN+MZQZmaDWpGzrb6c\n712+CtgN+GxEzK08MjMza1v9Jg9JQ4Ab8+CIThhmZgY0aLaKiOeA5yVtO0DxmJlZByhyhflqYLGk\nueQzrgAi4oTKojIzs7ZWJHn8JD/MzMyAfpKHpJ0i4vcR4XGszMysm/76PH5am5D04wGIxczMOkR/\nyUN10y+rOhAzM+sc/SWP6GO6EEk7SvqFpLslLZX0iVw+StJcScvz3+3rtjlF0n2Slkk6uK58sqTF\nedk5ktTbc5qZ2cDoL3nsLWmVpL8Cr8zTqyT9VdKqAvteC3wqIvYA9gOmS9oDmAHMi4iJwLw8T152\nJLAncAhwbr7OBOCbwDRgYn4cUvqVmplZ0/SZPCJiSESMjIhtImJonq7Nj2y044h4LCLuyNN/Be4B\nxgGHsf5mUheTbi5FLr80ItZExAPAfcC+knYARkbErXmMrVl125iZWQsUvZ/HJpHUBfwjcBswNiIe\ny4seZ/0tbccBD9Vt9nAuG5ene5abmVmLVJ48JG0N/Bg4MSK6NXfVj9bbpOc6TtJCSQtXrlzZrN2a\nmVkPlSYPSVuSEsf3I6J2oeEfclMU+e8TufwRYMe6zcfnskfydM/yDUTE+RExJSKmjBkzpnkvxMzM\nuqkseeQzor4N3BMRZ9UtmgNMzdNTgSvryo+UtFW+ze1EYEFu4lolab+8z6PrtjEzsxYoMjzJxtof\n+ABpXKy7ctmpwEzSPUKOBR4E3g0QEUslzQbuJp2pNT0PzAhwPHARMBy4Lj/MzKxFKkseEfErul9o\nWO/APrY5Azijl/KFwF7Ni87MzDbFgJxtZWZmmxcnDzMzK83Jw8zMSnPyMDOz0pw8zMysNCcPMzMr\nzcnDzMxKc/IwM7PSnDzMzKw0Jw8zMyvNycPMzEpz8jAzs9KcPMzMrDQnDzMzK83Jw8zMSnPyMDOz\n0pw8zMysNCcPMzMrzcnDzMxKc/IwM7PSnDzMzKw0Jw8zMyvNycPMzEpz8jAzs9KcPMzMrDQnDzMz\nK83Jw8zMSnPyMDOz0oa2OgBrjq4Z17Q6hHVWzDy01SGYWcVc8zAzs9KcPMzMrDQnDzMzK83Jw8zM\nSnPyMDOz0pw8zMysNCcPMzMrzcnDzMxK65jkIekQScsk3SdpRqvjMTMbzDoieUgaAnwDeAuwB3CU\npD1aG5WZ2eDVEckD2Be4LyLuj4hngEuBw1ock5nZoNUpyWMc8FDd/MO5zMzMWkAR0eoYGpJ0BHBI\nRPxbnv8A8OqI+FiP9Y4DjsuzuwHLBjTQDY0G/tjiGMrqtJg7LV5wzAOl02Jul3h3jogxjVbqlFF1\nHwF2rJsfn8u6iYjzgfMHKqhGJC2MiCmtjqOMTou50+IFxzxQOi3mTou3U5qtbgcmSpog6QXAkcCc\nFsdkZjZodUTNIyLWSvoYcAMwBPhORCxtcVhmZoNWRyQPgIi4Fri21XGU1DZNaCV0WsydFi845oHS\naTF3VLwd0WFuZmbtpVP6PMzMrI04eRQk6XBJIWn3VsfSG0nPSbpL0lJJv5H0KUlb5GVTJJ0zADF0\nSXpvk/ZVez21R1cz9tssklb3mD9G0tdbFc+mkvSf+dj5bX6/X11wuy5JS1odx0Y8z7WStmvi/kLS\nmXXzJ0k6fSP3tZ2k4zdy2xWSRm/MtmV1TJ9HGzgK+FX+e9qm7kzS0IhYu8lRrfd0ROyT9/1i4AfA\nSOC0iFgILGzic/WlC3hvfu5Nte71NIMkkZppn2/WPjcXkl4DvA2YFBFr8pfPCzopjqKfp7rj4K2b\nFu0G1gD/Ium/I2JTr9XYDjgeOLfnggq+Nzaaax4FSNoaeC1wLOk0YSQdIGm+pMsl/U7S9/OBiaS3\n5rJFks6RdHUuP13SJZJuAS6R9EtJ+9Q9z68k7b2p8UbEE6SLJT+m5IC6GF5f92v+TknbSNpC0rk5\n5rn5V9kRef11v2RyDWZ+X/sBZgKvy2Wf3NTX0ZOkIZK+JOn2/Mv0w7l8a0nzJN0habGkw3J5l9Jg\nmrOAJXS/Vqgykt4u6bb8vtwoaWwur/3/fy1puaRpufyAfCxck+M9L/9PPiTp7Lr9TpP0lQpC3gH4\nY0SsAYiIP0bEo5I+m9/rJZLOrzu+JyvVbn8DTB+AOPo6Bnt+no6RdGX+XC6XdFpeb4PjoLZPSS/M\n7/tv8ut8T91rvCl/hm+QtEOD2NeSOrw3OO4ljZH04/xe3i5p/7r4T6pbb4lSDXsmsEv+HH0pHx83\nS5oD3J3X/WmObanSxdEDLyL8aPAA3gd8O0//DzAZOAD4C+mCxS2AX5MSzDDSUCoT8vo/BK7O06cD\ni4DheX4qcHae3hVYuAkxru6l7M/A2BxrLYargP3z9Nak2ucRpDPZtgBeAjwJHJHXWQGMztNTgPn9\n7Gfd8zThPX8OuCs/rshlxwGfydNbkWpTE/Jzj8zlo4H7AJFqQs8D+1VwTNTHdxfwe+Dredn2rD8Z\n5d+AM+v+/78Bhuc4HwJemt+3vwMvI52KPjf/T7YG/hfYsu7Ye0UFr2Xr/BruJf3afX0uH1W3ziXA\n2/P0b4F/ztNfApZUHEdfx+DpdP88HQM8Brwov8dL8vobHAe1fQLvAi6oK98W2DK/12Ny2XtIlwf0\n+/kj1fRX5H2cBJyel/0AeG2e3gm4py7+k+r2sSTH2lX/nubj4ynyd0r9/6budb6o53tV9cM1j2KO\nIg3GSP57VJ5eEBEPR2oKuYv0T98duD8iHsjr/LDHvuZExNN5+jLgbZK2BD4EXFRN+N3cApwl6QRg\nu0hV4NcCl0XE8xHxOPCLjdxPMz0dEfvkxztz2ZuBoyXdBdxG+pKYSEoU/0/Sb4EbSeOejc3bPBgR\ntzY5tp7x7QN8tm7ZeOAGSYuBTwN71i27MiKejtS08QvSoJ+QjqX7I+I50jHz2ohYDfycdIzsTkoi\ni5v9QvLzTCYl55XAjyQdA7wh16AWA28E9lTqJ9guIn6ZN79kAOLoT/3nCWBuRPwpl/2EdGxD38fB\nYuBNkr4o6XUR8RfS0EZ7AXPzsfYZ0v+0UfyrgFnACT0WHQR8Pe9rDjBSqTWjjAV13ykAJ+Sa362k\nGvXEkvvbZO7zaEDSKNIH5xWSgvTLMIBrSO2cNc9R7P18qjYREX+TNJc0QvC7SR+cZsX9shzTE8DL\n655zpqRrgLcCt0g6uMGu1rK+eXPYJuynGQR8PCJu6FaYvmDGAJMj4llJK+pifYqB9zXgrIiYI+kA\n0i/Mmp7nxkeD8guBU4HfAd9tbph1T5aS1nxgfk4WHwZeCUyJiIeUOn+H9b2HyuKYSh/HYNbz/9vX\n+9jrcRAR90qaRDqO/0vSPOAKYGlEvGYjXsLZwB10/19tQar1/L1+RUn1rwv6f3/XxZ+PqYOA1+Tv\nkPkNtq2Eax6NHQFcEhE7R0RXROwIPAC8ro/1lwEv0/qzg97TYP8XAucAt0fEk02IF0ljgPNIzSjR\nY9kuEbE4Ir5IGvZld1It4l25nb3WzFWzgvVJ7V0N9vNXYJtmvIY+3AB8NNfUkLSrpBeSmgmeyInj\nDcDOFcZQxLasH3ttao9lh0kaJulFpPf59ly+r9LwO1uQjplfAUTEbaRflu9lw1psU0jaTVL9L9d9\nWD+o6B/zr+Qjcjx/Bv4sqfaL/n0Vx/EgfRyDfXiTpFGShgOHk47t/p7zpcDfIuJ7pCa4SaTXPkap\nAx9JW0ras5/drBMR/wfMJvWP1vwM+Hjdc9b6OVfk5yMnsAm5vNHnaFvgyZw4dgf2KxJbs7nm0dhR\nwBd7lP0Y+CipPbqbiHha6TS76yU9xfovh15FxCJJq9j0X5XDc7V4S9IvtUuAs3pZ78T8Bfs8sBS4\nDngWOJDUGfcQ6ZfTX/L6nwO+LekLpF+E/e3neeC5XJ2+KCKa3bl7Ialp8I7cebuS9AXxfeCq/Et1\nIelXeiudDlwm6UlSs9OEumW/JTVXjQa+EKlDeFfScfJ14B/y8ivqtpkN7NOsHxe92Br4Wm6SWkvq\nMzqO1Ge2BHic7sfxB4Hv5Jr4zwYgjpfT+zHYmwWkz+d44HsRsVD9n+b9CuBLkp4nfQ4+GhHPKJ0w\nco6kbUnfk2eTjvMizgTqR/w+AfhGblYdCvwS+EiO82hJS0nNsPcCRMSfJN2idAr0daRWjnrXAx+R\ndA8p0VXRLNuQrzCvgKStI2J1/oL7BrC8ry/S/MtnPrB7tPA00rqYX0T6AO6f+z+sSXLTz+qI+HKP\n8gNIHadv62O7q4GvRMS8yoPsYLn5ckr0uFWDVcPNVtWYlmsBS0lVzG/1tpKko0m/OP6zlYkjuzrH\nfDPpF7ETR4spXSx2L6lz3onD2oprHmZmVpprHmZmVpqTh5mZlebkYWZmpTl52GZDTRiJV9LnJR3U\nYJ2L8qmcvZU/UPf8/1P2+asi6SP5BA2zpvB1HrY52eSReCPis43X6tenI+LyTdzHOmrSKKoRcV4z\n4jGrcc3DNmtKI6rerDTi7h2S/qlu2clKo/D+RtLMXLauVqE+RpXdiBi+KumzefpgpRF0t8jPdZ6k\nhZLulfS2vM4xkuZI+jkwL5d9WutHE/5cLutrRNiZku7O6345l60bwVXSPpJuzcuvkLR9Lp+vNMbT\nghxPX6MomLnmYZuV2lX2AA/kARWfAN4UEX/PQ1/8EJgi6S2kMcVenYd5GNXL/r4eEZ8HkHQJ6V4T\nVzWI4UuSPpOnl0bE+4BTgNsl3UwaiuatEfF8zkVdpMERdwF+Iekf8raTgFdGxP9JejNp4Lt9SeN7\nzZH0z6TxvB6NiENzjNvmizzfSbroNNT7DY9mkcYIu0nS50n3pzkxLxsaEftKemsu77cJzwYvJw/b\nnPTWbLUlaUTTfUgDRe6ayw8CvhsRf4N1YxL19AZJ/wGMAEaRLvpslDw2aLbKyWkaaViKT0ZE/bA2\ns/MFossl3U8aIwzS6LC1mN6cH3fm+a1JyeRm4ExJXyQNhX+zpKGk4d2/na9Mv7o+ljzcxnYRcVMu\nupg0unPNT/LfRaTEZtYrJw/b3H0S+AOwN6mZ9u/9r55IGka6p0SzRpV9BfAn0v076hUZBVbAf0fE\nBiMVqMeIsBHxeUn7ksYqO4I0xtIbS8RZGym66CjRNki5z8M2d9sCj+Vf9x8gDakP6YZLH5Q0AtYN\nvV+vlii6jSq7MSTtDHwK+EfgLep+X+5/zf0fu5BuBrWsl13cAHwox4GkcZJerF5GhM3rbBsR15IS\nZ7c7U+b7VTxZ15/xAeAmzEryLwvb3J0L/Difpno9+Rd9RFyfm7IWSnqGdCfFU2sbRcSfJV1A76PK\n9qe+zwPg1cC3SQMfPirpWOAiSa/Ky39PGohyJPCR3DfTbYcR8TNJLwd+nZetBt5PGoG324iwpKG8\nr8w1JwH/3kuMU4HzcuK8nzRKrlkpHtvKrEUkXUTqq2jaqb1mA8XNVmZmVpprHmZmVpprHmZmVpqT\nh5mZlebkYWZmpTl5mJlZaU4eZmZWmpOHmZmV9v8B23oF+ohGFiEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ebd0cd8710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# seeing the distribution of each emotion in the dataset\n",
    "\n",
    "frequency_list = np.zeros(7)\n",
    "\n",
    "for label in labels:\n",
    "    frequency_list[int(label)] += 1\n",
    "    \n",
    "emotion_indices = range(1,8)\n",
    "\n",
    "x_axis_labels = ['Angry','Disgust','Fear','Happy','Sad','Surprise',\n",
    "         'Neutral']\n",
    "\n",
    "\n",
    "bar = plt.bar(emotion_indices, frequency_list, align='center')\n",
    "\n",
    "plt.xticks(emotion_indices, x_axis_labels )\n",
    "\n",
    "plt.xlabel(\"Facial Expression\")\n",
    "\n",
    "plt.ylabel(\"Frequency of Occurence\")\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'CV_GRAY2RGB'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-520469f6a058>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcolor_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m48\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m48\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCV_GRAY2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'CV_GRAY2RGB'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "color_img = cv2.cvtColor(samples[3].reshape(48,48), cv2.CV_GRAY2RGB)\n",
    "\n",
    "ax.imshow(color_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-d382dc7f38bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m48\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mvalid_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m48\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m48\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrain_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-d0e44bee81e0>\u001b[0m in \u001b[0;36mdf_to_tensor\u001b[1;34m(X_in, im_dim)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mpixel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mpixel_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpixel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mpixel_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpixel_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mim_dim\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpixel_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mim_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_tensors = df_to_tensor(X_train,48).astype('float32')/255\n",
    "valid_tensors = df_to_tensor(X_val,48).astype('float32')/255\n",
    "test_tensors = df_to_tensor(X_test,48).astype('float32')/255\n",
    "\n",
    "train_targets = np.array(pd.get_dummies(y_train))\n",
    "valid_targets = np.array(pd.get_dummies(y_val))\n",
    "test_targets = np.array(pd.get_dummies(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width = 48\n",
    "img_height = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu',\n",
    "                 input_shape=(img_width, img_height, 1)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=256, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "### TODO: specify the number of epochs that you would like to use to train the model.\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "### Do NOT modify the code below this line.\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(train_tensors, train_targets, \n",
    "          validation_data=(valid_tensors, valid_targets),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/weights.best.from_scratch.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get index of predicted facial expression for test set images\n",
    "expression_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(expression_predictions)==np.argmax(test_targets, axis=1))/len(expression_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, explore transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'applications' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fdc41b6a7fdf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model = applications.resnet50.ResNet50(weights=\"imagenet\", include_top=False,\n\u001b[0m\u001b[0;32m      2\u001b[0m                           input_shape=(48,48,3))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'applications' is not defined"
     ]
    }
   ],
   "source": [
    "model = applications.resnet50.ResNet50(weights=\"imagenet\", include_top=False,\n",
    "                          input_shape=(48,48,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22967, 48, 48)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "X_train_transf, X_test_transf, X_val_transf = X_train, X_test, X_val\n",
    "\n",
    "y_train_transf, y_test_transf, y_val_transf = y_train, y_test, y_val\n",
    "\n",
    "\n",
    "sample = df_to_tensor(X_train_transf, 48, reshape=False)\n",
    "\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[129],\n",
       "         [128],\n",
       "         [127],\n",
       "         ..., \n",
       "         [ 34],\n",
       "         [ 38],\n",
       "         [ 38]],\n",
       "\n",
       "        [[128],\n",
       "         [126],\n",
       "         [125],\n",
       "         ..., \n",
       "         [ 42],\n",
       "         [ 41],\n",
       "         [ 40]],\n",
       "\n",
       "        [[128],\n",
       "         [126],\n",
       "         [124],\n",
       "         ..., \n",
       "         [ 52],\n",
       "         [ 45],\n",
       "         [ 43]],\n",
       "\n",
       "        ..., \n",
       "        [[ 63],\n",
       "         [ 38],\n",
       "         [ 45],\n",
       "         ..., \n",
       "         [ 54],\n",
       "         [ 36],\n",
       "         [ 98]],\n",
       "\n",
       "        [[ 90],\n",
       "         [ 65],\n",
       "         [ 41],\n",
       "         ..., \n",
       "         [ 45],\n",
       "         [ 35],\n",
       "         [105]],\n",
       "\n",
       "        [[ 94],\n",
       "         [ 81],\n",
       "         [ 65],\n",
       "         ..., \n",
       "         [ 45],\n",
       "         [ 36],\n",
       "         [112]]],\n",
       "\n",
       "\n",
       "       [[[100],\n",
       "         [ 88],\n",
       "         [ 88],\n",
       "         ..., \n",
       "         [180],\n",
       "         [226],\n",
       "         [203]],\n",
       "\n",
       "        [[ 86],\n",
       "         [ 94],\n",
       "         [ 90],\n",
       "         ..., \n",
       "         [189],\n",
       "         [224],\n",
       "         [203]],\n",
       "\n",
       "        [[ 94],\n",
       "         [ 87],\n",
       "         [ 91],\n",
       "         ..., \n",
       "         [211],\n",
       "         [209],\n",
       "         [195]],\n",
       "\n",
       "        ..., \n",
       "        [[162],\n",
       "         [186],\n",
       "         [199],\n",
       "         ..., \n",
       "         [ 82],\n",
       "         [ 81],\n",
       "         [ 89]],\n",
       "\n",
       "        [[162],\n",
       "         [185],\n",
       "         [196],\n",
       "         ..., \n",
       "         [ 64],\n",
       "         [ 78],\n",
       "         [ 84]],\n",
       "\n",
       "        [[165],\n",
       "         [186],\n",
       "         [196],\n",
       "         ..., \n",
       "         [ 69],\n",
       "         [ 73],\n",
       "         [ 79]]],\n",
       "\n",
       "\n",
       "       [[[  0],\n",
       "         [  1],\n",
       "         [  0],\n",
       "         ..., \n",
       "         [ 85],\n",
       "         [ 49],\n",
       "         [ 19]],\n",
       "\n",
       "        [[  0],\n",
       "         [  2],\n",
       "         [  0],\n",
       "         ..., \n",
       "         [ 94],\n",
       "         [ 75],\n",
       "         [ 39]],\n",
       "\n",
       "        [[  0],\n",
       "         [  2],\n",
       "         [  0],\n",
       "         ..., \n",
       "         [102],\n",
       "         [ 84],\n",
       "         [ 57]],\n",
       "\n",
       "        ..., \n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ..., \n",
       "         [ 98],\n",
       "         [ 84],\n",
       "         [ 75]],\n",
       "\n",
       "        [[  7],\n",
       "         [  7],\n",
       "         [  7],\n",
       "         ..., \n",
       "         [ 98],\n",
       "         [ 85],\n",
       "         [ 80]],\n",
       "\n",
       "        [[ 66],\n",
       "         [ 67],\n",
       "         [ 64],\n",
       "         ..., \n",
       "         [126],\n",
       "         [118],\n",
       "         [112]]],\n",
       "\n",
       "\n",
       "       ..., \n",
       "       [[[ 46],\n",
       "         [ 99],\n",
       "         [131],\n",
       "         ..., \n",
       "         [ 58],\n",
       "         [ 30],\n",
       "         [ 18]],\n",
       "\n",
       "        [[ 54],\n",
       "         [114],\n",
       "         [101],\n",
       "         ..., \n",
       "         [ 74],\n",
       "         [ 36],\n",
       "         [ 30]],\n",
       "\n",
       "        [[ 70],\n",
       "         [108],\n",
       "         [101],\n",
       "         ..., \n",
       "         [ 84],\n",
       "         [ 48],\n",
       "         [ 48]],\n",
       "\n",
       "        ..., \n",
       "        [[131],\n",
       "         [150],\n",
       "         [169],\n",
       "         ..., \n",
       "         [ 11],\n",
       "         [ 33],\n",
       "         [ 40]],\n",
       "\n",
       "        [[139],\n",
       "         [125],\n",
       "         [ 79],\n",
       "         ..., \n",
       "         [ 35],\n",
       "         [ 40],\n",
       "         [ 16]],\n",
       "\n",
       "        [[ 54],\n",
       "         [ 12],\n",
       "         [  0],\n",
       "         ..., \n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]]],\n",
       "\n",
       "\n",
       "       [[[231],\n",
       "         [229],\n",
       "         [230],\n",
       "         ..., \n",
       "         [214],\n",
       "         [212],\n",
       "         [209]],\n",
       "\n",
       "        [[230],\n",
       "         [228],\n",
       "         [228],\n",
       "         ..., \n",
       "         [215],\n",
       "         [213],\n",
       "         [209]],\n",
       "\n",
       "        [[230],\n",
       "         [228],\n",
       "         [227],\n",
       "         ..., \n",
       "         [216],\n",
       "         [215],\n",
       "         [209]],\n",
       "\n",
       "        ..., \n",
       "        [[238],\n",
       "         [237],\n",
       "         [229],\n",
       "         ..., \n",
       "         [ 26],\n",
       "         [ 29],\n",
       "         [ 20]],\n",
       "\n",
       "        [[236],\n",
       "         [237],\n",
       "         [232],\n",
       "         ..., \n",
       "         [ 35],\n",
       "         [ 40],\n",
       "         [ 43]],\n",
       "\n",
       "        [[235],\n",
       "         [236],\n",
       "         [236],\n",
       "         ..., \n",
       "         [ 50],\n",
       "         [ 65],\n",
       "         [ 85]]],\n",
       "\n",
       "\n",
       "       [[[121],\n",
       "         [119],\n",
       "         [123],\n",
       "         ..., \n",
       "         [122],\n",
       "         [122],\n",
       "         [126]],\n",
       "\n",
       "        [[124],\n",
       "         [121],\n",
       "         [133],\n",
       "         ..., \n",
       "         [121],\n",
       "         [121],\n",
       "         [125]],\n",
       "\n",
       "        [[116],\n",
       "         [117],\n",
       "         [133],\n",
       "         ..., \n",
       "         [131],\n",
       "         [124],\n",
       "         [118]],\n",
       "\n",
       "        ..., \n",
       "        [[117],\n",
       "         [114],\n",
       "         [111],\n",
       "         ..., \n",
       "         [ 82],\n",
       "         [140],\n",
       "         [100]],\n",
       "\n",
       "        [[ 93],\n",
       "         [101],\n",
       "         [105],\n",
       "         ..., \n",
       "         [ 52],\n",
       "         [145],\n",
       "         [ 95]],\n",
       "\n",
       "        [[ 61],\n",
       "         [ 74],\n",
       "         [ 81],\n",
       "         ..., \n",
       "         [ 59],\n",
       "         [ 87],\n",
       "         [ 79]]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.reshape(sample.shape[0],48,48,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_two = df_to_tensor(X_train_transf, 48, reshape=False, triple_channels=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22967, 48, 48, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_two.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating transfer tensors\n",
    "\n",
    "train_tensors_transf = df_to_tensor(X_train_transf,48,reshape=False, triple_channels=True).astype('float32')/255\n",
    "valid_tensors_transf = df_to_tensor(X_val_transf,48, reshape=False, triple_channels=True).astype('float32')/255\n",
    "test_tensors_transf = df_to_tensor(X_test_transf,48, reshape=False, triple_channels=True).astype('float32')/255\n",
    "\n",
    "train_targets_transf = np.array(pd.get_dummies(y_train_transf))\n",
    "valid_targets_transf = np.array(pd.get_dummies(y_val_transf))\n",
    "test_targets_transf = np.array(pd.get_dummies(y_test_transf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
      "95469568/96112376 [============================>.] - ETA: 0s____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, None, None, 3) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, None, None, 32 864         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, None, None, 32 96          conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, None, None, 32 0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, None, None, 32 9216        activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, None, None, 32 96          conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, None, None, 32 0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, None, None, 64 18432       activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, None, None, 64 192         conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, None, None, 64 0           batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, None, None, 64 0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, None, None, 80 5120        max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, None, None, 80 240         conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, None, None, 80 0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, None, None, 19 138240      activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, None, None, 19 576         conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, None, None, 19 0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, None, None, 19 0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, None, None, 64 12288       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, None, None, 64 192         conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, None, None, 64 0           batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, None, None, 48 9216        max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, None, None, 96 55296       activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, None, None, 48 144         conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, None, None, 96 288         conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, None, None, 48 0           batch_normalization_7[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, None, None, 96 0           batch_normalization_10[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePool (None, None, None, 19 0           max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, None, None, 64 12288       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, None, None, 64 76800       activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, None, None, 96 82944       activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, None, None, 32 6144        average_pooling2d_1[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, None, None, 64 192         conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, None, None, 64 192         conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, None, None, 96 288         conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, None, None, 32 96          conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, None, None, 64 0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, None, None, 64 0           batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, None, None, 96 0           batch_normalization_11[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, None, None, 32 0           batch_normalization_12[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)             (None, None, None, 25 0           activation_6[0][0]               \n",
      "                                                                   activation_8[0][0]               \n",
      "                                                                   activation_11[0][0]              \n",
      "                                                                   activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)               (None, None, None, 64 16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNor (None, None, None, 64 192         conv2d_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, None, None, 64 0           batch_normalization_16[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)               (None, None, None, 48 12288       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)               (None, None, None, 96 55296       activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNor (None, None, None, 48 144         conv2d_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNor (None, None, None, 96 288         conv2d_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, None, None, 48 0           batch_normalization_14[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, None, None, 96 0           batch_normalization_17[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePool (None, None, None, 25 0           mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)               (None, None, None, 64 16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)               (None, None, None, 64 76800       activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)               (None, None, None, 96 82944       activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)               (None, None, None, 64 16384       average_pooling2d_2[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNor (None, None, None, 64 192         conv2d_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNor (None, None, None, 64 192         conv2d_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNor (None, None, None, 96 288         conv2d_18[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNor (None, None, None, 64 192         conv2d_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, None, None, 64 0           batch_normalization_13[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, None, None, 64 0           batch_normalization_15[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, None, None, 96 0           batch_normalization_18[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, None, None, 64 0           batch_normalization_19[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)             (None, None, None, 28 0           activation_13[0][0]              \n",
      "                                                                   activation_15[0][0]              \n",
      "                                                                   activation_18[0][0]              \n",
      "                                                                   activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, None, None, 64 18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNor (None, None, None, 64 192         conv2d_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, None, None, 64 0           batch_normalization_23[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)               (None, None, None, 48 13824       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)               (None, None, None, 96 55296       activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNor (None, None, None, 48 144         conv2d_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNor (None, None, None, 96 288         conv2d_24[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, None, None, 48 0           batch_normalization_21[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, None, None, 96 0           batch_normalization_24[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePool (None, None, None, 28 0           mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, None, None, 64 18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, None, None, 64 76800       activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)               (None, None, None, 96 82944       activation_24[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)               (None, None, None, 64 18432       average_pooling2d_3[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNor (None, None, None, 64 192         conv2d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNor (None, None, None, 64 192         conv2d_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNor (None, None, None, 96 288         conv2d_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNor (None, None, None, 64 192         conv2d_26[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, None, None, 64 0           batch_normalization_20[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, None, None, 64 0           batch_normalization_22[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, None, None, 96 0           batch_normalization_25[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, None, None, 64 0           batch_normalization_26[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)             (None, None, None, 28 0           activation_20[0][0]              \n",
      "                                                                   activation_22[0][0]              \n",
      "                                                                   activation_25[0][0]              \n",
      "                                                                   activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)               (None, None, None, 64 18432       mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNor (None, None, None, 64 192         conv2d_28[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_28 (Activation)       (None, None, None, 64 0           batch_normalization_28[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)               (None, None, None, 96 55296       activation_28[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNor (None, None, None, 96 288         conv2d_29[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_29 (Activation)       (None, None, None, 96 0           batch_normalization_29[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)               (None, None, None, 38 995328      mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)               (None, None, None, 96 82944       activation_29[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNor (None, None, None, 38 1152        conv2d_27[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNor (None, None, None, 96 288         conv2d_30[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_27 (Activation)       (None, None, None, 38 0           batch_normalization_27[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_30 (Activation)       (None, None, None, 96 0           batch_normalization_30[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, None, None, 28 0           mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)             (None, None, None, 76 0           activation_27[0][0]              \n",
      "                                                                   activation_30[0][0]              \n",
      "                                                                   max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)               (None, None, None, 12 98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNor (None, None, None, 12 384         conv2d_35[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_35 (Activation)       (None, None, None, 12 0           batch_normalization_35[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)               (None, None, None, 12 114688      activation_35[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNor (None, None, None, 12 384         conv2d_36[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_36 (Activation)       (None, None, None, 12 0           batch_normalization_36[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)               (None, None, None, 12 98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)               (None, None, None, 12 114688      activation_36[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNor (None, None, None, 12 384         conv2d_32[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNor (None, None, None, 12 384         conv2d_37[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_32 (Activation)       (None, None, None, 12 0           batch_normalization_32[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_37 (Activation)       (None, None, None, 12 0           batch_normalization_37[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)               (None, None, None, 12 114688      activation_32[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)               (None, None, None, 12 114688      activation_37[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNor (None, None, None, 12 384         conv2d_33[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNor (None, None, None, 12 384         conv2d_38[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_33 (Activation)       (None, None, None, 12 0           batch_normalization_33[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_38 (Activation)       (None, None, None, 12 0           batch_normalization_38[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePool (None, None, None, 76 0           mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)               (None, None, None, 19 147456      mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)               (None, None, None, 19 172032      activation_33[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)               (None, None, None, 19 172032      activation_38[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)               (None, None, None, 19 147456      average_pooling2d_4[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNor (None, None, None, 19 576         conv2d_31[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNor (None, None, None, 19 576         conv2d_34[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNor (None, None, None, 19 576         conv2d_39[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNor (None, None, None, 19 576         conv2d_40[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_31 (Activation)       (None, None, None, 19 0           batch_normalization_31[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_34 (Activation)       (None, None, None, 19 0           batch_normalization_34[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_39 (Activation)       (None, None, None, 19 0           batch_normalization_39[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_40 (Activation)       (None, None, None, 19 0           batch_normalization_40[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)             (None, None, None, 76 0           activation_31[0][0]              \n",
      "                                                                   activation_34[0][0]              \n",
      "                                                                   activation_39[0][0]              \n",
      "                                                                   activation_40[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)               (None, None, None, 16 122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNor (None, None, None, 16 480         conv2d_45[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_45 (Activation)       (None, None, None, 16 0           batch_normalization_45[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)               (None, None, None, 16 179200      activation_45[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNor (None, None, None, 16 480         conv2d_46[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_46 (Activation)       (None, None, None, 16 0           batch_normalization_46[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)               (None, None, None, 16 122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)               (None, None, None, 16 179200      activation_46[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNor (None, None, None, 16 480         conv2d_42[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNor (None, None, None, 16 480         conv2d_47[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_42 (Activation)       (None, None, None, 16 0           batch_normalization_42[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_47 (Activation)       (None, None, None, 16 0           batch_normalization_47[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)               (None, None, None, 16 179200      activation_42[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)               (None, None, None, 16 179200      activation_47[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNor (None, None, None, 16 480         conv2d_43[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNor (None, None, None, 16 480         conv2d_48[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_43 (Activation)       (None, None, None, 16 0           batch_normalization_43[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_48 (Activation)       (None, None, None, 16 0           batch_normalization_48[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePool (None, None, None, 76 0           mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)               (None, None, None, 19 147456      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)               (None, None, None, 19 215040      activation_43[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)               (None, None, None, 19 215040      activation_48[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)               (None, None, None, 19 147456      average_pooling2d_5[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNor (None, None, None, 19 576         conv2d_41[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNor (None, None, None, 19 576         conv2d_44[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNor (None, None, None, 19 576         conv2d_49[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNor (None, None, None, 19 576         conv2d_50[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_41 (Activation)       (None, None, None, 19 0           batch_normalization_41[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_44 (Activation)       (None, None, None, 19 0           batch_normalization_44[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_49 (Activation)       (None, None, None, 19 0           batch_normalization_49[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_50 (Activation)       (None, None, None, 19 0           batch_normalization_50[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)             (None, None, None, 76 0           activation_41[0][0]              \n",
      "                                                                   activation_44[0][0]              \n",
      "                                                                   activation_49[0][0]              \n",
      "                                                                   activation_50[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)               (None, None, None, 16 122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNor (None, None, None, 16 480         conv2d_55[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_55 (Activation)       (None, None, None, 16 0           batch_normalization_55[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)               (None, None, None, 16 179200      activation_55[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNor (None, None, None, 16 480         conv2d_56[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_56 (Activation)       (None, None, None, 16 0           batch_normalization_56[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)               (None, None, None, 16 122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)               (None, None, None, 16 179200      activation_56[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNor (None, None, None, 16 480         conv2d_52[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNor (None, None, None, 16 480         conv2d_57[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_52 (Activation)       (None, None, None, 16 0           batch_normalization_52[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_57 (Activation)       (None, None, None, 16 0           batch_normalization_57[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)               (None, None, None, 16 179200      activation_52[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)               (None, None, None, 16 179200      activation_57[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNor (None, None, None, 16 480         conv2d_53[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNor (None, None, None, 16 480         conv2d_58[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_53 (Activation)       (None, None, None, 16 0           batch_normalization_53[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_58 (Activation)       (None, None, None, 16 0           batch_normalization_58[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePool (None, None, None, 76 0           mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)               (None, None, None, 19 147456      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)               (None, None, None, 19 215040      activation_53[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)               (None, None, None, 19 215040      activation_58[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)               (None, None, None, 19 147456      average_pooling2d_6[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNor (None, None, None, 19 576         conv2d_51[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNor (None, None, None, 19 576         conv2d_54[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNor (None, None, None, 19 576         conv2d_59[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNor (None, None, None, 19 576         conv2d_60[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_51 (Activation)       (None, None, None, 19 0           batch_normalization_51[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_54 (Activation)       (None, None, None, 19 0           batch_normalization_54[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_59 (Activation)       (None, None, None, 19 0           batch_normalization_59[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_60 (Activation)       (None, None, None, 19 0           batch_normalization_60[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)             (None, None, None, 76 0           activation_51[0][0]              \n",
      "                                                                   activation_54[0][0]              \n",
      "                                                                   activation_59[0][0]              \n",
      "                                                                   activation_60[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)               (None, None, None, 19 147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNor (None, None, None, 19 576         conv2d_65[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_65 (Activation)       (None, None, None, 19 0           batch_normalization_65[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)               (None, None, None, 19 258048      activation_65[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNor (None, None, None, 19 576         conv2d_66[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_66 (Activation)       (None, None, None, 19 0           batch_normalization_66[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)               (None, None, None, 19 147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)               (None, None, None, 19 258048      activation_66[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNor (None, None, None, 19 576         conv2d_62[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNor (None, None, None, 19 576         conv2d_67[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_62 (Activation)       (None, None, None, 19 0           batch_normalization_62[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_67 (Activation)       (None, None, None, 19 0           batch_normalization_67[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)               (None, None, None, 19 258048      activation_62[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)               (None, None, None, 19 258048      activation_67[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNor (None, None, None, 19 576         conv2d_63[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNor (None, None, None, 19 576         conv2d_68[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_63 (Activation)       (None, None, None, 19 0           batch_normalization_63[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_68 (Activation)       (None, None, None, 19 0           batch_normalization_68[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePool (None, None, None, 76 0           mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)               (None, None, None, 19 147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)               (None, None, None, 19 258048      activation_63[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)               (None, None, None, 19 258048      activation_68[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)               (None, None, None, 19 147456      average_pooling2d_7[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNor (None, None, None, 19 576         conv2d_61[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNor (None, None, None, 19 576         conv2d_64[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNor (None, None, None, 19 576         conv2d_69[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNor (None, None, None, 19 576         conv2d_70[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_61 (Activation)       (None, None, None, 19 0           batch_normalization_61[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_64 (Activation)       (None, None, None, 19 0           batch_normalization_64[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_69 (Activation)       (None, None, None, 19 0           batch_normalization_69[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_70 (Activation)       (None, None, None, 19 0           batch_normalization_70[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)             (None, None, None, 76 0           activation_61[0][0]              \n",
      "                                                                   activation_64[0][0]              \n",
      "                                                                   activation_69[0][0]              \n",
      "                                                                   activation_70[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)               (None, None, None, 19 147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNor (None, None, None, 19 576         conv2d_73[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_73 (Activation)       (None, None, None, 19 0           batch_normalization_73[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)               (None, None, None, 19 258048      activation_73[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNor (None, None, None, 19 576         conv2d_74[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_74 (Activation)       (None, None, None, 19 0           batch_normalization_74[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)               (None, None, None, 19 147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)               (None, None, None, 19 258048      activation_74[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNor (None, None, None, 19 576         conv2d_71[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNor (None, None, None, 19 576         conv2d_75[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_71 (Activation)       (None, None, None, 19 0           batch_normalization_71[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_75 (Activation)       (None, None, None, 19 0           batch_normalization_75[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)               (None, None, None, 32 552960      activation_71[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)               (None, None, None, 19 331776      activation_75[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNor (None, None, None, 32 960         conv2d_72[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNor (None, None, None, 19 576         conv2d_76[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_72 (Activation)       (None, None, None, 32 0           batch_normalization_72[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_76 (Activation)       (None, None, None, 19 0           batch_normalization_76[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (None, None, None, 76 0           mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)             (None, None, None, 12 0           activation_72[0][0]              \n",
      "                                                                   activation_76[0][0]              \n",
      "                                                                   max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)               (None, None, None, 44 573440      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNor (None, None, None, 44 1344        conv2d_81[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_81 (Activation)       (None, None, None, 44 0           batch_normalization_81[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)               (None, None, None, 38 491520      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)               (None, None, None, 38 1548288     activation_81[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNor (None, None, None, 38 1152        conv2d_78[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNor (None, None, None, 38 1152        conv2d_82[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_78 (Activation)       (None, None, None, 38 0           batch_normalization_78[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_82 (Activation)       (None, None, None, 38 0           batch_normalization_82[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)               (None, None, None, 38 442368      activation_78[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)               (None, None, None, 38 442368      activation_78[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)               (None, None, None, 38 442368      activation_82[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)               (None, None, None, 38 442368      activation_82[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePool (None, None, None, 12 0           mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)               (None, None, None, 32 409600      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNor (None, None, None, 38 1152        conv2d_79[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNor (None, None, None, 38 1152        conv2d_80[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNor (None, None, None, 38 1152        conv2d_83[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNor (None, None, None, 38 1152        conv2d_84[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)               (None, None, None, 19 245760      average_pooling2d_8[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNor (None, None, None, 32 960         conv2d_77[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_79 (Activation)       (None, None, None, 38 0           batch_normalization_79[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_80 (Activation)       (None, None, None, 38 0           batch_normalization_80[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_83 (Activation)       (None, None, None, 38 0           batch_normalization_83[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_84 (Activation)       (None, None, None, 38 0           batch_normalization_84[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNor (None, None, None, 19 576         conv2d_85[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_77 (Activation)       (None, None, None, 32 0           batch_normalization_77[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)           (None, None, None, 76 0           activation_79[0][0]              \n",
      "                                                                   activation_80[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, None, None, 76 0           activation_83[0][0]              \n",
      "                                                                   activation_84[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_85 (Activation)       (None, None, None, 19 0           batch_normalization_85[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)             (None, None, None, 20 0           activation_77[0][0]              \n",
      "                                                                   mixed9_0[0][0]                   \n",
      "                                                                   concatenate_1[0][0]              \n",
      "                                                                   activation_85[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)               (None, None, None, 44 917504      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNor (None, None, None, 44 1344        conv2d_90[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_90 (Activation)       (None, None, None, 44 0           batch_normalization_90[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)               (None, None, None, 38 786432      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)               (None, None, None, 38 1548288     activation_90[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNor (None, None, None, 38 1152        conv2d_87[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNor (None, None, None, 38 1152        conv2d_91[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_87 (Activation)       (None, None, None, 38 0           batch_normalization_87[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_91 (Activation)       (None, None, None, 38 0           batch_normalization_91[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)               (None, None, None, 38 442368      activation_87[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)               (None, None, None, 38 442368      activation_87[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)               (None, None, None, 38 442368      activation_91[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)               (None, None, None, 38 442368      activation_91[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePool (None, None, None, 20 0           mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)               (None, None, None, 32 655360      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNor (None, None, None, 38 1152        conv2d_88[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNor (None, None, None, 38 1152        conv2d_89[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNor (None, None, None, 38 1152        conv2d_92[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNor (None, None, None, 38 1152        conv2d_93[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)               (None, None, None, 19 393216      average_pooling2d_9[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNor (None, None, None, 32 960         conv2d_86[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_88 (Activation)       (None, None, None, 38 0           batch_normalization_88[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_89 (Activation)       (None, None, None, 38 0           batch_normalization_89[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_92 (Activation)       (None, None, None, 38 0           batch_normalization_92[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "activation_93 (Activation)       (None, None, None, 38 0           batch_normalization_93[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNor (None, None, None, 19 576         conv2d_94[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_86 (Activation)       (None, None, None, 32 0           batch_normalization_86[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)           (None, None, None, 76 0           activation_88[0][0]              \n",
      "                                                                   activation_89[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, None, None, 76 0           activation_92[0][0]              \n",
      "                                                                   activation_93[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_94 (Activation)       (None, None, None, 19 0           batch_normalization_94[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)            (None, None, None, 20 0           activation_86[0][0]              \n",
      "                                                                   mixed9_1[0][0]                   \n",
      "                                                                   concatenate_2[0][0]              \n",
      "                                                                   activation_94[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2D (None, 2048)          0           mixed10[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "predictions (Dense)              (None, 1000)          2049000     avg_pool[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 23,851,784\n",
      "Trainable params: 23,817,352\n",
      "Non-trainable params: 34,432\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Note: the code below is an adaptation of a code snippet by Prakash Jay,\n",
    "# obtained from: https://towardsdatascience.com/transfer-learning-using-keras-d804b2e04ef8\n",
    "\n",
    "img_width, img_height = 48, 48\n",
    "\"\"\"\n",
    "train_data_dir = \"data/train\"\n",
    "validation_data_dir = \"data/val\"\n",
    "nb_train_samples = 4125\n",
    "nb_validation_samples = 466 \n",
    "\"\"\"\n",
    "batch_size = 16\n",
    "epochs = 50\n",
    "\n",
    "model = applications.inception_v3.InceptionV3(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\"\"\"\n",
    "\n",
    "#allow training in initial layers for now, to see what the result is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# duplicate of prakash jay code\n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(7, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22967 samples, validate on 5742 samples\n",
      "Epoch 1/20\n",
      "22940/22967 [============================>.] - ETA: 0s - loss: 1.8841 - acc: 0.2141Epoch 00000: val_loss improved from inf to 1.75099, saving model to saved_models/weights.best.transfer_example_five.hdf5\n",
      "22967/22967 [==============================] - 52s - loss: 1.8841 - acc: 0.2141 - val_loss: 1.7510 - val_acc: 0.2957\n",
      "Epoch 2/20\n",
      "22940/22967 [============================>.] - ETA: 0s - loss: 1.7902 - acc: 0.2578Epoch 00001: val_loss improved from 1.75099 to 1.71442, saving model to saved_models/weights.best.transfer_example_five.hdf5\n",
      "22967/22967 [==============================] - 51s - loss: 1.7900 - acc: 0.2579 - val_loss: 1.7144 - val_acc: 0.3144\n",
      "Epoch 3/20\n",
      "22940/22967 [============================>.] - ETA: 0s - loss: 1.7519 - acc: 0.2847Epoch 00002: val_loss improved from 1.71442 to 1.69250, saving model to saved_models/weights.best.transfer_example_five.hdf5\n",
      "22967/22967 [==============================] - 51s - loss: 1.7520 - acc: 0.2846 - val_loss: 1.6925 - val_acc: 0.3333\n",
      "Epoch 4/20\n",
      "22940/22967 [============================>.] - ETA: 0s - loss: 1.7284 - acc: 0.2987Epoch 00003: val_loss improved from 1.69250 to 1.67814, saving model to saved_models/weights.best.transfer_example_five.hdf5\n",
      "22967/22967 [==============================] - 51s - loss: 1.7283 - acc: 0.2987 - val_loss: 1.6781 - val_acc: 0.3398\n",
      "Epoch 5/20\n",
      "22940/22967 [============================>.] - ETA: 0s - loss: 1.7110 - acc: 0.3077Epoch 00004: val_loss improved from 1.67814 to 1.66960, saving model to saved_models/weights.best.transfer_example_five.hdf5\n",
      "22967/22967 [==============================] - 51s - loss: 1.7109 - acc: 0.3077 - val_loss: 1.6696 - val_acc: 0.3422\n",
      "Epoch 6/20\n",
      "22940/22967 [============================>.] - ETA: 0s - loss: 1.7021 - acc: 0.3149Epoch 00005: val_loss improved from 1.66960 to 1.66184, saving model to saved_models/weights.best.transfer_example_five.hdf5\n",
      "22967/22967 [==============================] - 51s - loss: 1.7021 - acc: 0.3149 - val_loss: 1.6618 - val_acc: 0.3457\n",
      "Epoch 7/20\n",
      "22940/22967 [============================>.] - ETA: 0s - loss: 1.6966 - acc: 0.3173Epoch 00006: val_loss improved from 1.66184 to 1.65621, saving model to saved_models/weights.best.transfer_example_five.hdf5\n",
      "22967/22967 [==============================] - 51s - loss: 1.6966 - acc: 0.3172 - val_loss: 1.6562 - val_acc: 0.3434\n",
      "Epoch 8/20\n",
      "22940/22967 [============================>.] - ETA: 0s - loss: 1.6859 - acc: 0.3259Epoch 00007: val_loss improved from 1.65621 to 1.65136, saving model to saved_models/weights.best.transfer_example_five.hdf5\n",
      "22967/22967 [==============================] - 51s - loss: 1.6860 - acc: 0.3259 - val_loss: 1.6514 - val_acc: 0.3457\n",
      "Epoch 9/20\n",
      "22940/22967 [============================>.] - ETA: 0s - loss: 1.6802 - acc: 0.3274Epoch 00008: val_loss improved from 1.65136 to 1.64667, saving model to saved_models/weights.best.transfer_example_five.hdf5\n",
      "22967/22967 [==============================] - 51s - loss: 1.6804 - acc: 0.3273 - val_loss: 1.6467 - val_acc: 0.3523\n",
      "Epoch 10/20\n",
      "22940/22967 [============================>.] - ETA: 0s - loss: 1.6732 - acc: 0.3299Epoch 00009: val_loss improved from 1.64667 to 1.64263, saving model to saved_models/weights.best.transfer_example_five.hdf5\n",
      "22967/22967 [==============================] - 51s - loss: 1.6731 - acc: 0.3298 - val_loss: 1.6426 - val_acc: 0.3532\n",
      "Epoch 11/20\n",
      "22940/22967 [============================>.] - ETA: 0s - loss: 1.6733 - acc: 0.3321Epoch 00010: val_loss improved from 1.64263 to 1.64036, saving model to saved_models/weights.best.transfer_example_five.hdf5\n",
      "22967/22967 [==============================] - 51s - loss: 1.6733 - acc: 0.3320 - val_loss: 1.6404 - val_acc: 0.3483\n",
      "Epoch 12/20\n",
      "22940/22967 [============================>.] - ETA: 0s - loss: 1.6681 - acc: 0.3323Epoch 00011: val_loss improved from 1.64036 to 1.63633, saving model to saved_models/weights.best.transfer_example_five.hdf5\n",
      "22967/22967 [==============================] - 51s - loss: 1.6680 - acc: 0.3323 - val_loss: 1.6363 - val_acc: 0.3568\n",
      "Epoch 13/20\n",
      "22940/22967 [============================>.] - ETA: 0s - loss: 1.6627 - acc: 0.3343Epoch 00012: val_loss improved from 1.63633 to 1.63258, saving model to saved_models/weights.best.transfer_example_five.hdf5\n",
      "22967/22967 [==============================] - 51s - loss: 1.6626 - acc: 0.3345 - val_loss: 1.6326 - val_acc: 0.3516\n",
      "Epoch 14/20\n",
      "22940/22967 [============================>.] - ETA: 0s - loss: 1.6612 - acc: 0.3359Epoch 00013: val_loss improved from 1.63258 to 1.63028, saving model to saved_models/weights.best.transfer_example_five.hdf5\n",
      "22967/22967 [==============================] - 51s - loss: 1.6610 - acc: 0.3359 - val_loss: 1.6303 - val_acc: 0.3513\n",
      "Epoch 15/20\n",
      "22940/22967 [============================>.] - ETA: 0s - loss: 1.6537 - acc: 0.3436Epoch 00014: val_loss improved from 1.63028 to 1.62557, saving model to saved_models/weights.best.transfer_example_five.hdf5\n",
      "22967/22967 [==============================] - 51s - loss: 1.6539 - acc: 0.3436 - val_loss: 1.6256 - val_acc: 0.3570\n",
      "Epoch 16/20\n",
      "22940/22967 [============================>.] - ETA: 0s - loss: 1.6515 - acc: 0.3452Epoch 00015: val_loss improved from 1.62557 to 1.62508, saving model to saved_models/weights.best.transfer_example_five.hdf5\n",
      "22967/22967 [==============================] - 51s - loss: 1.6515 - acc: 0.3452 - val_loss: 1.6251 - val_acc: 0.3577\n",
      "Epoch 17/20\n",
      "22940/22967 [============================>.] - ETA: 0s - loss: 1.6495 - acc: 0.3432Epoch 00016: val_loss improved from 1.62508 to 1.62085, saving model to saved_models/weights.best.transfer_example_five.hdf5\n",
      "22967/22967 [==============================] - 51s - loss: 1.6493 - acc: 0.3433 - val_loss: 1.6208 - val_acc: 0.3621\n",
      "Epoch 18/20\n",
      "22940/22967 [============================>.] - ETA: 0s - loss: 1.6456 - acc: 0.3439Epoch 00017: val_loss improved from 1.62085 to 1.61894, saving model to saved_models/weights.best.transfer_example_five.hdf5\n",
      "22967/22967 [==============================] - 51s - loss: 1.6458 - acc: 0.3438 - val_loss: 1.6189 - val_acc: 0.3633\n",
      "Epoch 19/20\n",
      "22940/22967 [============================>.] - ETA: 0s - loss: 1.6462 - acc: 0.3454Epoch 00018: val_loss improved from 1.61894 to 1.61728, saving model to saved_models/weights.best.transfer_example_five.hdf5\n",
      "22967/22967 [==============================] - 51s - loss: 1.6461 - acc: 0.3454 - val_loss: 1.6173 - val_acc: 0.3584\n",
      "Epoch 20/20\n",
      "22940/22967 [============================>.] - ETA: 0s - loss: 1.6439 - acc: 0.3485Epoch 00019: val_loss improved from 1.61728 to 1.61496, saving model to saved_models/weights.best.transfer_example_five.hdf5\n",
      "22967/22967 [==============================] - 51s - loss: 1.6438 - acc: 0.3485 - val_loss: 1.6150 - val_acc: 0.3643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4fda44dfd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.transfer_example_six.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model_final.fit(train_tensors_transf, train_targets_transf, \n",
    "          validation_data=(valid_tensors_transf, valid_targets_transf),\n",
    "          epochs=20, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_final.load_weights('saved_models/weights.best.transfer_example_five.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 37.0577%\n"
     ]
    }
   ],
   "source": [
    "# get index of predicted facial expression for test set images\n",
    "expression_predictions_transf = [np.argmax(model_final.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors_transf]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(expression_predictions_transf)==np.argmax(test_targets_transf, axis=1))/len(expression_predictions_transf)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BELOW: INCEPTION RESNET V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 48, 48, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 48, 48, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 48, 48\n",
    "\"\"\"\n",
    "train_data_dir = \"data/train\"\n",
    "validation_data_dir = \"data/val\"\n",
    "nb_train_samples = 4125\n",
    "nb_validation_samples = 466 \n",
    "\"\"\"\n",
    "batch_size = 16\n",
    "epochs = 50\n",
    "\n",
    "#this time, using inception resnetv2\n",
    "\n",
    "model_irv2 = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 48, 48, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 48, 48, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 7175      \n",
      "=================================================================\n",
      "Total params: 21,606,471\n",
      "Trainable params: 21,606,471\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# duplicate of prakash jay code\n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(7, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
